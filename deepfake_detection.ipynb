{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66304760-a234-40fd-bf7b-0fefe5558981",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66304760-a234-40fd-bf7b-0fefe5558981",
        "outputId": "e2045414-d74f-47d9-8a46-6ff4dd527af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (1.1.1)\n",
            "Requirement already satisfied: tensorflow in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (2.20.0)\n",
            "Requirement already satisfied: opencv-python-headless in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: gradio in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (5.49.1)\n",
            "Collecting kaggle\n",
            "  Using cached kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from efficientnet) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.2.6)\n",
            "Requirement already satisfied: h5py in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (6.32.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (3.11.3)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: audioop-lts<1.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.2.2)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.119.0)\n",
            "Requirement already satisfied: ffmpy in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.6.3)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (2.3.3)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.14.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio-client==1.13.3->gradio) (2025.9.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\n",
            "Collecting bleach (from kaggle)\n",
            "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting text-unidecode (from kaggle)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting webencodings (from kaggle)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: namex in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from scikit-image->efficientnet) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from scikit-image->efficientnet) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from scikit-image->efficientnet) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from scikit-image->efficientnet) (2025.10.4)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /home/uppercase/Workspace/.venv/lib/python3.13/site-packages (from scikit-image->efficientnet) (0.4)\n",
            "Using cached kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
            "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: webencodings, text-unidecode, python-slugify, bleach, kaggle\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [kaggle]2m4/5\u001b[0m [kaggle]\n",
            "\u001b[1A\u001b[2KSuccessfully installed bleach-6.2.0 kaggle-1.7.4.5 python-slugify-8.0.4 text-unidecode-1.3 webencodings-0.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install face_recognition efficientnet tensorflow opencv-python-headless gradio kaggle \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Hetu909H4k7_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hetu909H4k7_",
        "outputId": "54d2b483-a806-4b45-db80-6db9984181f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# dataset link --   https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "OauWQmVQyOTX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OauWQmVQyOTX",
        "outputId": "04e303e1-3832-4b3e-ff4a-173e45692ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n",
            "License(s): unknown\n",
            "Downloading deepfake-and-real-images.zip to /content\n",
            " 99% 1.67G/1.68G [00:23<00:00, 319MB/s]\n",
            "100% 1.68G/1.68G [00:23<00:00, 77.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d manjilkarki/deepfake-and-real-images\n",
        "!unzip -q deepfake-and-real-images.zip -d dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d78db24",
      "metadata": {},
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94aa6a2-0f81-4ec7-ac5c-22bcfcc9a570",
      "metadata": {
        "id": "e94aa6a2-0f81-4ec7-ac5c-22bcfcc9a570"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/uppercase/Workspace/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2025-10-15 01:48:01.936114: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-10-15 01:48:01.944020: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-15 01:48:02.224791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-10-15 01:48:03.741010: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-10-15 01:48:03.742773: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from pathlib import Path\n",
        "from PIL import Image \n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac5aff12",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760472098.327696    3226 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
            "W0000 00:00:1760472098.411566    3226 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Ty4vIyzbBmSJ",
      "metadata": {
        "id": "Ty4vIyzbBmSJ"
      },
      "outputs": [],
      "source": [
        "def load_images(folder, label, size=(244, 244)):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder):\n",
        "        path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(path)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, size)\n",
        "            data.append((img, label))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d475403d",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_path = \"/home/uppercase/Workspace/Lab Projects/ML/deepfake_detection\"\n",
        "\n",
        "train_real = f\"{base_path}/Dataset/Train/Real\"\n",
        "train_fake = f\"{base_path}/Dataset/Train/Fake\"\n",
        "\n",
        "test_real = f\"{base_path}/Dataset/Test/Real\"\n",
        "test_fake = f\"{base_path}/Dataset/Test/Fake\"\n",
        "\n",
        "val_real = f\"{base_path}/Dataset/Validation/Real\"\n",
        "val_fake = f\"{base_path}/Dataset/Validation/Fake\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0e793ea2",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_real_data =  load_images(train_real, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13eb18b1",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'load_images' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_fake_data =  \u001b[43mload_images\u001b[49m(train_fake, \u001b[32m1\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'load_images' is not defined"
          ]
        }
      ],
      "source": [
        "train_fake_data =  load_images(train_fake, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b04395",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = train_real_data + train_fake_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d12633",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_real_data =  load_images(test_real, 0)\n",
        "test_fake_data =  load_images(test_fake, 1)\n",
        "test_data = test_real_data + test_fake_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cb935f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "val_real_data =  load_images(val_real, 0)\n",
        "val_fake_data =  load_images(val_fake, 1)\n",
        "val_data = val_real_data + val_fake_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c225f18b-1cac-4233-8348-73be74c25164",
      "metadata": {
        "id": "c225f18b-1cac-4233-8348-73be74c25164"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert to NumPy with reduced memory usage\n",
        "X_train = np.array([item[0] for item in train_data], dtype=np.float32) / 255.0\n",
        "y_train = np.array([item[1] for item in train_data])\n",
        "y_train = to_categorical(y, num_classes=2)\n",
        "\n",
        "X_test = np.array([item[0] for item in test_data], dtype=np.float32) / 255.0\n",
        "y_test = np.array([item[1] for item in test_data])\n",
        "y_test = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "X_val = np.array([item[0] for item in val_data], dtype=np.float32) / 255.0\n",
        "y_val = np.array([item[1] for item in val_data])\n",
        "y_val = to_categorical(y_val, num_classes=2)\n",
        "\n",
        "\n",
        "# Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "903579af-6f9e-4c6f-a587-a5272a34adf8",
      "metadata": {
        "id": "903579af-6f9e-4c6f-a587-a5272a34adf8"
      },
      "outputs": [],
      "source": [
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(244, 244, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=16),\n",
        "    epochs=5,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "model.save(\"deepfake_detector_efficientnetb4.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963ae29d-6ab8-4388-9c8c-d17ae89e41f9",
      "metadata": {
        "id": "963ae29d-6ab8-4388-9c8c-d17ae89e41f9"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Step 4: Recompile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Continue training (fine-tuning)\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=16),\n",
        "    epochs=5,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "# Step 6: Save the fine-tuned model\n",
        "model.save(\"deepfake_detector_efficientnetb4_finetuned.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9902c00-4c8a-41c7-912e-ce81a220bb7b",
      "metadata": {
        "id": "f9902c00-4c8a-41c7-912e-ce81a220bb7b"
      },
      "outputs": [],
      "source": [
        "\n",
        "known_faces = []\n",
        "known_names = []\n",
        "\n",
        "dataset_path = Path(r\"D:\\new_project\\face_dataset\")\n",
        "\n",
        "# Accept common image file extensions\n",
        "valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "\n",
        "for img_path in dataset_path.rglob(\"*\"):\n",
        "    if img_path.suffix.lower() not in valid_extensions:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        image = face_recognition.load_image_file(str(img_path))\n",
        "        encodings = face_recognition.face_encodings(image)\n",
        "\n",
        "        if encodings:\n",
        "            known_faces.append(encodings[0])\n",
        "            name = img_path.parent.name  # Use folder name as label\n",
        "            known_names.append(name)\n",
        "        else:\n",
        "            print(f\"No face found in: {img_path.name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path.name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "186d9779-8038-4050-b8df-3724b60e675d",
      "metadata": {
        "id": "186d9779-8038-4050-b8df-3724b60e675d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load your trained model before prediction\n",
        "model = load_model(\"deepfake_detector_efficientnetb4_finetuned.h5\")\n",
        "\n",
        "def predict_and_recognize(image, is_webcam=False):\n",
        "    try:\n",
        "        # Deepfake Detection (always performed)\n",
        "        # Webcam input is resized and processed for deepfake detection\n",
        "        image_resized = cv2.resize(image, (244, 244)) / 255.0\n",
        "        input_tensor = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "        pred = model.predict(input_tensor)[0]\n",
        "        predicted_class = np.argmax(pred)\n",
        "        confidence = round(float(np.max(pred)) * 100, 2)\n",
        "\n",
        "        is_real = predicted_class == 0 and confidence >= 50.0  # Adjusted threshold slightly\n",
        "        result = \"Real\" if is_real else \"Fake\"\n",
        "        full_result = f\"{result} Face ({confidence}% Confidence)\"\n",
        "\n",
        "        # Removed Face recognition part due to CUDA error with face_recognition library\n",
        "\n",
        "        return full_result # Return only deepfake detection result\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during prediction: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "716fc826-6497-49fb-85b7-f5f7c207d839",
      "metadata": {
        "id": "716fc826-6497-49fb-85b7-f5f7c207d839"
      },
      "outputs": [],
      "source": [
        "# Load your trained model before prediction (re-added here in case it was removed elsewhere)\n",
        "# model = load_model(\"deepfake_detector_efficientnetb4_finetuned.h5\") # Assuming model is loaded in a previous cell\n",
        "\n",
        "interface = gr.Interface(fn=predict_and_recognize,\n",
        "                         inputs=gr.Image(type=\"numpy\", label=\"Upload or Capture Face Image\"),\n",
        "                         outputs=\"text\",\n",
        "                         title=\"Deepfake Detection\", # Updated title\n",
        "                         description=\"Upload a face image or use your webcam to detect if it's a deepfake.\") # Updated description\n",
        "\n",
        "interface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935d802d-2639-46b1-b462-c1aa7bbec976",
      "metadata": {
        "id": "935d802d-2639-46b1-b462-c1aa7bbec976"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
