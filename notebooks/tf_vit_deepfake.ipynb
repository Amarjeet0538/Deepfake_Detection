{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf531fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 09:46:48.657742: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-25 09:46:48.694938: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-25 09:46:49.721119: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhub\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     22\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m2\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow_hub'"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from tqdm import tqdm as notebook_tqdm\n",
    "from pkg_resources import parse_version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83362acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b5d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 190335 images with 190335 labels\n"
     ]
    }
   ],
   "source": [
    "file_names = []\n",
    "labels = []\n",
    "\n",
    "data_path = Path(\"/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset\")\n",
    "for file in sorted(data_path.glob(\"**/*.jpg\")):\n",
    "    label = file.parent.name\n",
    "    labels.append(label)\n",
    "    file_names.append(str(file))\n",
    "\n",
    "print(f\"Loaded {len(file_names)} images with {len(labels)} labels\")\n",
    "\n",
    "df = pd.DataFrame({\"image\": file_names, \"label\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef764c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "984f81e9-006b-4c93-b765-067f3ff5126a",
       "rows": [
        [
         "0",
         "/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset/Test/Fake/fake_0.jpg",
         "Fake"
        ],
        [
         "1",
         "/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset/Test/Fake/fake_1.jpg",
         "Fake"
        ],
        [
         "2",
         "/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset/Test/Fake/fake_10.jpg",
         "Fake"
        ],
        [
         "3",
         "/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset/Test/Fake/fake_100.jpg",
         "Fake"
        ],
        [
         "4",
         "/home/uppercase/Workspace/Projects/Deepfake_Detection/dataset/Test/Fake/fake_1000.jpg",
         "Fake"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/uppercase/Workspace/Projects/Deepfake_De...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/uppercase/Workspace/Projects/Deepfake_De...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/uppercase/Workspace/Projects/Deepfake_De...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/uppercase/Workspace/Projects/Deepfake_De...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/uppercase/Workspace/Projects/Deepfake_De...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image label\n",
       "0  /home/uppercase/Workspace/Projects/Deepfake_De...  Fake\n",
       "1  /home/uppercase/Workspace/Projects/Deepfake_De...  Fake\n",
       "2  /home/uppercase/Workspace/Projects/Deepfake_De...  Fake\n",
       "3  /home/uppercase/Workspace/Projects/Deepfake_De...  Fake\n",
       "4  /home/uppercase/Workspace/Projects/Deepfake_De...  Fake"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dcf908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake' 'Real']\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca03cd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: (190402, 2)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "ros = RandomOverSampler(random_state=83)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df[\"label\"] = y_resampled\n",
    "\n",
    "del X, y\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Resampled dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10cc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['label'])\n",
    "df['label'] = df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114241 validated image filenames belonging to 2 classes.\n",
      "Found 76161 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "labels_list = ['Real', 'Fake']\n",
    "label2id = {label: i for i, label in enumerate(labels_list)}\n",
    "id2label = {i: label for i, label in enumerate(labels_list)}\n",
    "\n",
    "df['label_int'] = df['label'].map(label2id)\n",
    "df['label_str'] = df['label']\n",
    "\n",
    "train_df = df.sample(frac=0.6, random_state=83)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    train_df, x_col=\"image\", y_col=\"label_str\",\n",
    "    target_size=(224, 224), batch_size=16, class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    test_df, x_col=\"image\", y_col=\"label_str\",\n",
    "    target_size=(224, 224), batch_size=8, class_mode='categorical', shuffle=False\n",
    ")\n",
    "\n",
    "train_labels = train_df['label_int'].values\n",
    "test_labels = test_df['label_int'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7461b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761305402.860948    3575 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2111 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vit_url = \"https://tfhub.dev/sayakpaul/vit_b16_fe/1\"\n",
    "vit_module = hub.load(vit_url)\n",
    "\n",
    "def vit_features(x):\n",
    "    return vit_module(x)\n",
    "\n",
    "def build_vit_model(num_classes=2):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = layers.Lambda(vit_features)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_vit_model()\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=2e-5),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb924a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3d5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint('best_vit_model.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a6f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train generator output shape: (16, 2)\n",
      "Test generator output shape: (8, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train generator output shape:\", next(train_generator)[1].shape)\n",
    "print(\"Test generator output shape:\", next(test_generator)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d28b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uppercase/Workspace/Projects/Deepfake_Detection/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 17:00:10.856229: I external/local_xla/xla/service/service.cc:163] XLA service 0x7d401400b500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-24 17:00:10.856263: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-10-24 17:00:11.028610: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-24 17:00:11.697145: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-24 17:00:13.269312: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_132', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:13.928530: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_133', 528 bytes spill stores, 396 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:14.129289: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_109', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:14.178799: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_109', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:14.399228: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_133', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:14.440782: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:16.074397: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:16.163153: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:16.412193: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 360 bytes spill stores, 360 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:16.647790: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:16.934787: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_133', 400 bytes spill stores, 304 bytes spill loads\n",
      "\n",
      "2025-10-24 17:00:17.040258: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/7141\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23:49:04\u001b[0m 12s/step - accuracy: 0.4375 - loss: 1.6047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761305419.209292    3830 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2374/7141\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:13\u001b[0m 129ms/step - accuracy: 0.5607 - loss: 1.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 17:05:27.095920: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_96', 40 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:27.400848: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_123', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:27.459843: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:27.788437: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:28.102160: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_123', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:28.264949: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:28.344263: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_97', 404 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:28.356482: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 376 bytes spill stores, 376 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:29.414780: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:29.430558: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:29.730376: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "2025-10-24 17:05:29.774592: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 10956 bytes spill stores, 10116 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.5902 - loss: 1.3069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 17:15:55.737412: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_132', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:55.954707: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_133', 528 bytes spill stores, 396 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:56.765635: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:56.936581: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_109', 384 bytes spill stores, 384 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:57.840233: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_109', 180 bytes spill stores, 180 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:57.858020: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2496', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:58.644957: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_7', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:58.685819: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 360 bytes spill stores, 360 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:59.007168: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 392 bytes spill stores, 392 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:59.118885: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_6', 200 bytes spill stores, 200 bytes spill loads\n",
      "\n",
      "2025-10-24 17:15:59.252955: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5', 96 bytes spill stores, 96 bytes spill loads\n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1612s\u001b[0m 224ms/step - accuracy: 0.6290 - loss: 1.1125 - val_accuracy: 0.7463 - val_loss: 0.5667 - learning_rate: 2.0000e-05\n",
      "Epoch 2/12\n",
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7018 - loss: 0.7798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1592s\u001b[0m 223ms/step - accuracy: 0.7127 - loss: 0.7265 - val_accuracy: 0.7888 - val_loss: 0.4617 - learning_rate: 2.0000e-05\n",
      "Epoch 3/12\n",
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7405 - loss: 0.6005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1659s\u001b[0m 232ms/step - accuracy: 0.7469 - loss: 0.5740 - val_accuracy: 0.8081 - val_loss: 0.4197 - learning_rate: 2.0000e-05\n",
      "Epoch 4/12\n",
      "\u001b[1m7141/7141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7631 - loss: 0.5150"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,  # Let generator handle labels\n",
    "    epochs=12,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define confusion matrix plotting function\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.0f'\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_prob = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = test_labels[:len(y_pred)]  # Use pre-extracted integer labels\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "if len(labels_list) <= 150:\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
