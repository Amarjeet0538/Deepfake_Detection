{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf1a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/preprocess.py\n",
    "import cv2, numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from pathlib import Path\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def crop_face(img: np.ndarray, margin=40):\n",
    "    \"\"\"Return 256x256 face-centered crop or None.\"\"\"\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = detector.detect_faces(rgb)\n",
    "    if not faces:\n",
    "        return None\n",
    "    x, y, w, h = faces[0]['box']\n",
    "    x1 = max(x - margin, 0)\n",
    "    y1 = max(y - margin, 0)\n",
    "    x2 = x + w + margin\n",
    "    y2 = y + h + margin\n",
    "    face = rgb[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (256, 256))\n",
    "    return face\n",
    "\n",
    "def preprocess_folder(src: str, dst: str):\n",
    "    Path(dst).mkdir(parents=True, exist_ok=True)\n",
    "    for f in Path(src).glob(\"*.jpg\"):\n",
    "        img = cv2.imread(str(f))\n",
    "        cropped = crop_face(img)\n",
    "        if cropped is not None:\n",
    "            cv2.imwrite(f\"{dst}/{f.name}\", cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/model.py\n",
    "from tensorflow.keras import layers, models, applications\n",
    "\n",
    "def build_xception():\n",
    "    base = applications.Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(256, 256, 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    base.trainable = True  # fine-tune all layers\n",
    "\n",
    "    inputs = layers.Input((256, 256, 3))\n",
    "    x = applications.xception.preprocess_input(inputs)\n",
    "    x = base(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(2, activation='softmax', dtype='float32')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', 'AUC']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/train.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from src.model import build_xception\n",
    "import os\n",
    "\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator()\n",
    "\n",
    "train = train_gen.flow_from_directory(\n",
    "    'data/train', target_size=IMG_SIZE, batch_size=BATCH,\n",
    "    class_mode='categorical', shuffle=True)\n",
    "\n",
    "val = val_gen.flow_from_directory(\n",
    "    'data/val', target_size=IMG_SIZE, batch_size=BATCH,\n",
    "    class_mode='categorical', shuffle=False)\n",
    "\n",
    "model = build_xception()\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint('models/best_xception.h5', save_best_only=True, monitor='val_auc', mode='max'),\n",
    "    EarlyStopping(monitor='val_auc', patience=8, restore_best_weights=True, mode='max'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4)\n",
    "]\n",
    "\n",
    "model.fit(train, validation_data=val, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c51ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/evaluate.py\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = load_model('models/best_xception.h5')\n",
    "test_gen = ImageDataGenerator().flow_from_directory(\n",
    "    'data/test', target_size=(256,256), batch_size=32,\n",
    "    class_mode='categorical', shuffle=False)\n",
    "\n",
    "y_prob = model.predict(test_gen)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['Real','Fake']))\n",
    "print(\"AUC:\", roc_auc_score(y_true, y_prob[:,1]))\n",
    "\n",
    "# Confusion matrix plot\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real','Fake'], yticklabels=['Real','Fake'])\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c36895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/inference.py\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/best_xception.h5')\n",
    "\n",
    "def predict_image(img_path: str, threshold: float = 0.5) -> str:\n",
    "    img = image.load_img(img_path, target_size=(256, 256))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = x / 255.0\n",
    "    prob_fake = float(model.predict(x, verbose=0)[0][1])\n",
    "    label = \"Fake\" if prob_fake >= threshold else \"Real\"\n",
    "    return f\"{label} ({prob_fake*100:.1f}% Fake)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/app.py\n",
    "import gradio as gr\n",
    "from src.inference import predict_image\n",
    "from PIL import Image\n",
    "\n",
    "def gradio_predict(img: Image.Image):\n",
    "    img.save(\"temp.jpg\")\n",
    "    return predict_image(\"temp.jpg\")\n",
    "\n",
    "gr.Interface(\n",
    "    gradio_predict,\n",
    "    gr.Image(type=\"pil\"),\n",
    "    gr.Textbox(),\n",
    "    title=\"Deepfake Image Detector\",\n",
    "    description=\"Upload any face → instantly know if it’s **Real** or **AI-generated**.\",\n",
    "    examples=[\n",
    "        [\"examples/real_01.jpg\"],\n",
    "        [\"examples/fake_01.jpg\"]\n",
    "    ]\n",
    ").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
